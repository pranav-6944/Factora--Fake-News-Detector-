# Factora - Fake News Detection System ğŸ§ ğŸ“°

**Factora** is an AI-powered full-stack fake news detection web app built with Python Flask and BERT-based NLP model. Developed during a virtual internship at **Pinnacle Labs**, it provides real-time prediction, analytics, and user feedback for detecting misinformation.

---

## ğŸš€ Key Features

- ğŸ¤– **AI-Powered Prediction**
  - Uses a fine-tuned DistilBERT model trained on the LIAR dataset for binary classification (FAKE or REAL).
- ğŸ” **User Authentication**
  - Secure login/signup with hashed passwords using Flask-Login.
- ğŸ“ˆ **Analytics Dashboard**
  - View total predictions, feedback accuracy, and interactive charts (via Chart.js).
- ğŸ“‚ **Prediction History + Search**
  - Stores per-user prediction history in SQLite3 with filtering/search support.
- ğŸ“° **Live News Headlines**
  - Integrates with News API to fetch and analyze latest headlines in real-time.
- ğŸ‘ **Feedback System**
  - Users can rate each prediction (accurate or wrong) to help improve the system.
- ğŸ§ª **Confidence Score**
  - Each prediction includes a probability score from the model.
- ğŸ’¾ **CSV Export**
  - Download prediction history in CSV format.
- ğŸ¨ **Modern UI + Responsive Design**
  - Fully mobile-friendly layout with animated transitions and dark/light support.

---

## ğŸ§° Tech Stack

### ğŸ”§ Backend
- Python
- Flask (with Jinja2 templating)
- Flask-Login
- SQLite3
- HuggingFace Transformers
- scikit-learn
- Joblib

### ğŸŒ Frontend
- HTML5, CSS3, JavaScript
- Chart.js
- Font Awesome

### ğŸ§  Machine Learning
- Model: DistilBERT (fine-tuned)
- Dataset: [LIAR dataset](https://www.cs.ucsb.edu/~william/data/liar_dataset.zip)
- Binary Labels: Fake = ["pants-fire", "false", "barely-true"], Real = ["half-true", "mostly-true", "true"]
- Text preprocessing included: lowercasing, punctuation removal, etc.

---

## ğŸ“ Folder Structure

Factora/
â”‚
â”œâ”€â”€ bert_model/ # Fine-tuned DistilBERT model
â”œâ”€â”€ bert_tokenizer/ # Tokenizer for DistilBERT
â”œâ”€â”€ database/ # SQLite DBs (auth.db, feedback.db, truthlens.db)
â”œâ”€â”€ liar_dataset/ # LIAR dataset (train.tsv, test.tsv, valid.tsv)
â”œâ”€â”€ static/ # CSS, JS, Images
â”œâ”€â”€ templates/ # HTML pages
â”œâ”€â”€ train_bert_liar.py # BERT training script
â”œâ”€â”€ predict_bert.py # Prediction using BERT model
â”œâ”€â”€ app.py # Flask backend
â”œâ”€â”€ config.py # Config file (paths, DB locations)
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # This file


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repo
```bash
git clone https://github.com/yourusername/Factora.git
cd Factora


2ï¸âƒ£ Create Virtual Environment

python -m venv venv
# Activate it
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate


3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt
4ï¸âƒ£ Download LIAR Dataset
Manually download LIAR dataset:
ğŸ”— LIAR Dataset (zip)
Extract files into: liar_dataset/

Make sure you have:

train.tsv

valid.tsv

test.tsv


5ï¸âƒ£ Train BERT Model

python train_bert_liar.py
â¡ï¸ Outputs saved to: bert_model/ and bert_tokenizer/


6ï¸âƒ£ Run the Web App

python app.py
Then open http://localhost:5000

ğŸ”’ Security Notes
Donâ€™t use app.run(debug=True) in production

Set a secure secret key in app.secret_key

Use HTTPS + WSGI server (Gunicorn / uWSGI) behind Nginx for deployment

Recommended: use .env files for sensitive configs

ğŸ§  Future Plans
 Integrate BERT model âœ…

 Admin panel to view user feedback

 Host on Render or Vercel

 Continuous retraining pipeline

ğŸ‘¨â€ğŸ’» Developer
Built with ğŸ’ª by Pranav (CS Student, MIT Academy of Engineering)
ğŸ¢ Internship: Pinnacle Labs
ğŸ“Œ From frontend â†’ backend â†’ ML training â†’ deployment â€” this is a solo build project.

Letâ€™s connect on LinkedIn ğŸ”— and work on more cool stuff together! ğŸš€


ğŸ“„ License
MIT License â€” open source for learning and non-commercial use.

PRs and contributions welcome!
